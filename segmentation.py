# -*- coding: utf-8 -*-
"""segmentation

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1VvgI7luBE2KFk4euRuF_0s6TBIRExqRx
"""

import cv2
import numpy as np
import os
import scipy.ndimage
from google.colab.patches import cv2_imshow



def getMeanArea(contours):
    meanArea=0
    for contour in contours:
        meanArea += cv2.contourArea(contour)
    meanArea=(meanArea)/len(contours)
    return meanArea



def meanY(contours):
    meanY=0
    
    for contour in contours:
        x,y,w,h=cv2.boundingRect(contour)
        meanY+=y
    meanY=(meanY)/len(contours)
    return meanY



def getMeanAreaa(contours):
    meana=0
    for contour in contours:
        x,y,w,h = cv2.boundingRect(contour)
        meana+=w*h

    meana=(meana)/len(contours)
    return meana



def extract_character(image, recursion = 0):
    thresh = cv2.copyMakeBorder(image, 8, 8, 8, 8, cv2.BORDER_REPLICATE)  #make border of 8 pixels in all drxn => BORDER_REPLICATE means => outermost pixel replicated => thus black border
    thresh = cv2.GaussianBlur(thresh, (3,3), 0)  # (3*3) kernel, standard dev. = 0  => means internally calculates standard dev.
    ret,thresh = cv2.threshold(thresh, 0, 255, cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)  #threshold => based on OTSU method => find optimal threshold based on the neighbourhood => applied thresh_binary => convert to binary and inverse
    # thresholding after greyscale => since in BGR => 3 channels => complicated
    # morphological operations are applied ONLY on binary images
    kernel1 = np.ones((3,3), np.uint8)
    kernel2 = np.ones((2,2), np.uint8)
    thresh = cv2.dilate(thresh, kernel1, iterations = 1)  #dialate using (3*3) kernel
    thresh = cv2.erode(thresh, kernel2, iterations = 2)   #erode using (2*2) kernel => twice
    thresh = cv2.dilate(thresh, kernel1, iterations = 1)  #dialate using (3*3) kernel

    # finding the contours
    # RETR_EXTERNAL => gets ONLY extreme outer contours => ignores contours inside the image (nested contours)
    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)  

    coords=[]
    count=0
    meanArea = getMeanArea(contours)   #mean contour areas
    meany = meanY(contours)
    
    for contour in contours:
        (x,y,w,h) = cv2.boundingRect(contour)

        if (cv2.contourArea(contour)>0.5* meanArea or w*h>0.5*meanArea) and (y+h>meany or cv2.contourArea(contour)>0.7* meanArea):
            if w / h > 3.5:                               
                if cv2.contourArea(contour) > 0.6 * meanArea:  #then split into 2 segments
                    half_width = int(w / 2)
                    coords.append((x, y, half_width, h))
                    coords.append((x + half_width, y, half_width, h))
                    count = count+2
            else:  
                coords.append((x, y, w, h))
                count = count+1
    
    coords = sorted(coords,key=lambda x: x[0])     #sort contours
    img_paths=[]

    if(count >1 and recursion <3):
    	img_paths_array = extract_character(image, recursion + 1)
    	return img_paths_array
    else:
      for i in range(count):
        result = thresh[coords[i][1]:coords[i][1]+coords[i][3], coords[i][0]:coords[i][0]+coords[i][2]]
        target_width = 30  # desired width
        aspect_ratio = result.shape[1] / result.shape[0]
        target_height = int(target_width / aspect_ratio)
        resized_image = cv2.resize(result, (target_width, target_height))
        cv2_imshow(resized_image)
      for i in range(count):
        filename = 'character'+str(i)+'.jpeg'
        img_paths.append(filename)

    return np.array(img_paths)
