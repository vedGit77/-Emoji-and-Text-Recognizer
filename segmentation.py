# -- coding: utf-8 --
"""segmentation

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1VvgI7luBE2KFk4euRuF_0s6TBIRExqRx
"""

import cv2
import numpy as np
import os
import scipy.ndimage
from google.colab.patches import cv2_imshow



def getMeanArea(contours):
    meanArea=0
    for contour in contours:
        meanArea += cv2.contourArea(contour)
    meanArea=(meanArea)/len(contours)
    return meanArea



def meanY(contours):
    meanY=0
    
    for contour in contours:
        x,y,w,h=cv2.boundingRect(contour)
        meanY+=y
    meanY=(meanY)/len(contours)
    return meanY



def getMeanAreaa(contours):
    meana=0
    for contour in contours:
        x,y,w,h = cv2.boundingRect(contour)
        meana+=w*h

    meana=(meana)/len(contours)
    return meana


def purify(img):
    img = cv2.copyMakeBorder(img,32,32,32,32,cv2.BORDER_CONSTANT)    #make border of 32 pixels in all drxn => BORDER_REPLICATE means => outermost pixel replicated => thus black border
    contours, _ = cv2.findContours(img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)  #RETR_EXTERNAL => gets only extreme outer contours => ignores contours inside the image (nested contours)
    meanArea = getMeanArea(contours)
    nlabels, labels, stats, _ = cv2.connectedComponentsWithStats(img,None,None,None,8,cv2.CV_32S)  #connectedComponentsWithStats => analyzes the connectivity of pixels in a binary image. provides statistics (such as area, centroid, bounding box, etc.) for each component.
    areas = stats[1:,cv2.CC_STAT_AREA]
    result = np.zeros((labels.shape),np.uint8)   #result is all zeroes
    
    for i in range(nlabels-1):
        if areas[i] >= 0.05*meanArea:
            result[labels==i+1] = 255
    
    high = max(result.shape[0],result.shape[1])
    
    if high==result.shape[0]:
        dif=(high-result.shape[1])//2
        result=cv2.copyMakeBorder(result,0,0,dif,dif,cv2.BORDER_CONSTANT,value=0)
    else:
        dif=(high-result.shape[1])//2
        result=cv2.copyMakeBorder(result,dif,dif,0,0,cv2.BORDER_CONSTANT,value=0)
    
    return cv2.resize(result,(28,28),interpolation=cv2.INTER_AREA)



def extract_character(image, recursion = 0):
    thresh = cv2.copyMakeBorder(image, 8, 8, 8, 8, cv2.BORDER_REPLICATE)  #make border of 8 pixels in all drxn => BORDER_REPLICATE means => outermost pixel replicated => thus black border
    thresh = cv2.GaussianBlur(thresh, (3,3), 0)  # (3*3) kernel, standard dev. = 0  => means internally calculates standard dev.
    ret,thresh = cv2.threshold(thresh, 0, 255, cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)  #threshold => based on OTSU method => find optimal threshold based on the neighbourhood => applied thresh_binary => convert to binary and inverse
    # thresholding after greyscale => since in BGR => 3 channels => complicated
    # morphological operations are applied ONLY on binary images
    kernel1 = np.ones((3,3), np.uint8)
    kernel2 = np.ones((2,2), np.uint8)
    thresh = cv2.dilate(thresh, kernel1, iterations = 1)  #dialate using (3*3) kernel
    thresh = cv2.erode(thresh, kernel2, iterations = 2)   #erode using (2*2) kernel => twice
    thresh = cv2.dilate(thresh, kernel1, iterations = 1)  #dialate using (3*3) kernel

    # finding the contours
    # RETR_EXTERNAL => gets ONLY extreme outer contours => ignores contours inside the image (nested contours)
    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)  

    coords=[]
    count=0
    meanArea = getMeanArea(contours)   #mean contour areas
    meany = meanY(contours)
    
    for contour in contours:
        (x,y,w,h) = cv2.boundingRect(contour)

        if (cv2.contourArea(contour)>0.5* meanArea or w*h>0.5*meanArea) and (y+h>meany or cv2.contourArea(contour)>0.7* meanArea):
            if w / h > 3.5:                               
                if cv2.contourArea(contour) > 0.6 * meanArea:  #then split into 2 segments
                    half_width = int(w / 2)
                    coords.append((x, y, half_width, h))
                    coords.append((x + half_width, y, half_width, h))
                    count = count+2
            else:  
                coords.append((x, y, w, h))
                count = count+1
    
    coords = sorted(coords,key=lambda x: x[0])     #sort contours
    img_paths=[]

    if(count >1 and recursion <3):
    	img_paths_array = extract_character(image, recursion + 1)
    	return img_paths_array
    else:
    	for i in range(count):
        	result = purify(thresh[coords[i][1]:coords[i][1]+coords[i][3], coords[i][0]:coords[i][0]+coords[i][2]])
        	cv2_imshow(result)
        	filename='character'+str(i)+'.jpeg'
        	cv2.imwrite(filename,cv2.bitwise_not(result))
        	img_paths.append(filename)
    	return np.array(img_paths)
